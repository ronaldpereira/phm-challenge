{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM Data Challenge 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = pd.read_csv(\"../data/Train - Part Consumption.csv\")\n",
    "\n",
    "consumption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = pd.read_csv(\"../data/Train - Usage.csv\")\n",
    "usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = pd.read_csv(\"../data/Train - Failures.csv\")\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(consumption.Reason)\n",
    "reason_count = c.most_common()\n",
    "reason_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(failures.Asset)\n",
    "failures_count = c.most_common()\n",
    "failures_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = consumption.query(\"Quantity <= 0\").index\n",
    "consumption.drop(indexes, inplace=True)\n",
    "consumption.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption.Quantity.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article plots reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_un = consumption.Asset.unique()\n",
    "print(assets_un)\n",
    "print(len(assets_un))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_usages = []\n",
    "std_usages = []\n",
    "for asset in tqdm(assets_un):\n",
    "    asset_usages = usage.query(\"Asset == @asset\").Use.to_list()\n",
    "    if len(asset_usages) > 0:\n",
    "        mean_usages.append(np.mean(asset_usages))\n",
    "        std_usages.append(np.std(asset_usages))\n",
    "\n",
    "mean_usages = list(map(lambda x: x / 1e4, mean_usages))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(mean_usages, bins=500)\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "plt.xlim(2.5, 3.6)\n",
    "plt.ylim(0, 100)\n",
    "plt.xlabel(\"Mean of usage $(10^4)$\", fontsize=15)\n",
    "plt.ylabel(\"Frequency count\", fontsize=15)\n",
    "plt.title(\"Histogram of assets usage mean\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(mean_usages, std_usages, \"ro\")\n",
    "plt.xlim(2.5, 3.6)\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlabel(\"Mean of usage\", fontsize=15)\n",
    "plt.ylabel(\"Std of usage\", fontsize=15)\n",
    "plt.title(\"Assets usage clustering\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_usages = []\n",
    "std_usages = []\n",
    "for asset in tqdm(assets_un):\n",
    "    asset_usages = usage.query(\"Asset == @asset\").Use.to_list()\n",
    "    if len(asset_usages) > 0:\n",
    "        mean_usages.append(np.mean(asset_usages) - asset_usages[0])\n",
    "        std_usages.append(np.std(asset_usages))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(mean_usages, bins=500)\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "plt.xlim(0, 3000)\n",
    "plt.xlabel(\"Mean of usage\", fontsize=15)\n",
    "plt.ylabel(\"Frequency count\", fontsize=15)\n",
    "plt.title(\"Histogram of assets usage mean after first measure\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = consumption.Part.unique()\n",
    "print(parts)\n",
    "print(len(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_cons, parts_cons = consumption.Asset, consumption.Part\n",
    "\n",
    "assets_parts = []\n",
    "for asset, part in zip(assets_cons, parts_cons):\n",
    "    assets_parts.append(asset + \"_\" + part)\n",
    "assets_parts = np.unique(assets_parts)\n",
    "\n",
    "print(len(assets_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_usages_mean = []\n",
    "parts_usages_std = []\n",
    "parts_usages_count = []\n",
    "assets = []\n",
    "parts = []\n",
    "for asset_part in tqdm(assets_parts):\n",
    "    asset, part = asset_part.split(\"_\")\n",
    "    consumptions_times = consumption.query(\"Asset == @asset and Part == @part\")\n",
    "\n",
    "    if len(consumptions_times) > 0:\n",
    "        try:\n",
    "            usage_asset_mean_each_t = mean_usages[list(assets_un).index(asset)] / 730\n",
    "            assets.append(asset)\n",
    "            parts.append(part)\n",
    "\n",
    "            usages_snapshots = []\n",
    "            for cons_time in consumptions_times.Time:\n",
    "                usages_snapshots.append(cons_time * usage_asset_mean_each_t)\n",
    "\n",
    "            parts_usages_mean.append(np.mean(usages_snapshots))\n",
    "            parts_usages_std.append(np.std(usages_snapshots))\n",
    "            parts_usages_count.append(len(usages_snapshots))\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(assets),\n",
    "    len(parts),\n",
    "    len(parts_usages_mean),\n",
    "    len(parts_usages_std),\n",
    "    len(parts_usages_count),\n",
    ")\n",
    "\n",
    "data = {\n",
    "    \"asset\": assets,\n",
    "    \"part\": parts,\n",
    "    \"consumption_usage_mean\": parts_usages_mean,\n",
    "    \"consumption_usage_std\": parts_usages_std,\n",
    "    \"consumption_counts\": parts_usages_count,\n",
    "}\n",
    "\n",
    "parts_usage_df = pd.DataFrame(data)\n",
    "parts_usage_df.to_csv(\"../data/parts_usages.csv\", index=False)\n",
    "parts_usage_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_un = parts_usage_df.part.unique()\n",
    "\n",
    "for part in parts_un:\n",
    "    print(parts_usage_df.query(\"part == @part\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = consumption.copy()\n",
    "train_df.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Failure\"] = [False] * train_df.shape[0]\n",
    "train_df[\"Time_failure\"] = [0] * train_df.shape[0]\n",
    "train_df[\"Time_diff\"] = [0] * train_df.shape[0]\n",
    "train_df[\"Usage_on_failure\"] = [0] * train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for fail_asset, fail_time in tqdm(list(failures.itertuples(index=False, name=None))):\n",
    "#     possible_cons = consumption.query(\"Time <= @fail_time and Asset == @fail_asset\")\n",
    "\n",
    "#     usage_next = usage.query(\"Time >= @fail_time and Asset == @fail_asset\").head(1)\n",
    "#     usage_prev = usage.query(\"Time <= @fail_time and Asset == @fail_asset\").tail(1)\n",
    "\n",
    "#     usage_failure_value = 0\n",
    "#     if len(usage_next) > 0 and len(usage_prev) > 0:\n",
    "#         usage_prev_time = usage_prev.iloc[0, 1]\n",
    "#         usage_prev_value = usage_prev.iloc[0, 2]\n",
    "#         usage_next_time = usage_next.iloc[0, 1]\n",
    "#         usage_next_value = usage_next.iloc[0, 2]\n",
    "\n",
    "#         if usage_next_time - usage_prev_time > 0:\n",
    "#             usage_failure_value = fail_time - usage_prev_time\n",
    "#             usage_failure_value /= usage_next_time - usage_prev_time\n",
    "#             usage_failure_value *= usage_next_value - usage_prev_value\n",
    "#             usage_failure_value += usage_prev_value\n",
    "#         else:\n",
    "#             usage_failure_value = usage_next_value\n",
    "\n",
    "#     inserted_parts = []\n",
    "#     for index, cons_part in possible_cons[::-1].iterrows():\n",
    "#         if cons_part.Part not in inserted_parts:\n",
    "#             train_df.loc[index, \"Failure\"] = True\n",
    "#             train_df.loc[index, \"Time_failure\"] = fail_time\n",
    "#             train_df.loc[index, \"Time_diff\"] = (\n",
    "#                 fail_time - consumption.loc[index, \"Time\"]\n",
    "#             )\n",
    "#             train_df.loc[index, \"Usage_on_failure\"] = usage_failure_value\n",
    "#             inserted_parts.append(cons_part.Part)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.query(\"Failure==True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../data/train_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This train set above does not really express others examples by considering some negative failures instances. So, I'll do this on Usage_on_failure column, by just measuring the usage on the Time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.drop([\"Time_failure\", \"Time_diff\", \"Usage_on_failure\"], axis=1, inplace=True)\n",
    "\n",
    "# for index, row in tqdm(train_df[[\"Asset\", \"Time\"]].iterrows()):\n",
    "#     time = row.Time\n",
    "#     asset = row.Asset\n",
    "#     usage_next = usage.query(\"Time >= @time and Asset == @asset\").head(1)\n",
    "#     usage_prev = usage.query(\"Time <= @time and Asset == @asset\").tail(1)\n",
    "\n",
    "#     usage_value = 0\n",
    "#     if len(usage_next) > 0 and len(usage_prev) > 0:\n",
    "#         usage_prev_time = usage_prev.iloc[0, 1]\n",
    "#         usage_prev_value = usage_prev.iloc[0, 2]\n",
    "#         usage_next_time = usage_next.iloc[0, 1]\n",
    "#         usage_next_value = usage_next.iloc[0, 2]\n",
    "\n",
    "#         if usage_next_time - usage_prev_time > 0:\n",
    "#             usage_value = row.Time - usage_prev_time\n",
    "#             usage_value /= usage_next_time - usage_prev_time\n",
    "#             usage_value *= usage_next_value - usage_prev_value\n",
    "#             usage_value += usage_prev_value\n",
    "#         else:\n",
    "#             usage_value = usage_next_value\n",
    "\n",
    "#     train_df.loc[index, \"Usage_on_time\"] = usage_value\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features_usage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../data/train_features_usage.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
